{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_common_starting_string(list_words):\n",
    "    \"\"\"\n",
    "    return the common string    \"\"\"\n",
    "    common = list_words[0]\n",
    "    for word in list_words[1:]:\n",
    "        i = 0\n",
    "        while (i < len(word) and i < len(common)):\n",
    "            if(common[i] != word[i]):\n",
    "                break\n",
    "            i += 1\n",
    "        common = common[:i]\n",
    "    return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_non_common_start(list_words, common):\n",
    "    \"\"\"\n",
    "    return the list of remaining strings    \"\"\"\n",
    "\n",
    "    list_non_common = list()\n",
    "    for word in list_words:\n",
    "        i = 0\n",
    "        for letter in common:\n",
    "            if(letter != word[i]):\n",
    "                print word[i:]\n",
    "                break\n",
    "            i += 1\n",
    "        list_non_common.append(word[i:])\n",
    "    return list_non_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorize_list_of_strings(list_words):\n",
    "    common = find_common_starting_string(list_words)\n",
    "    list_non_common = extract_non_common_start(list_words, common)\n",
    "    return common + '{' + ','.join(list_non_common) + '}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'th{us,e,read,ought,rough}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = ['thus', 'the', 'thread', 'thought', 'through']   #normal test case\n",
    "factorize_list_of_strings(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{thus,the,,thought,through}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = ['thus', 'the', '', 'thought', 'through']  #test list containing an empty string\n",
    "factorize_list_of_strings(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'th{us,eiuygjhkkllmetgfferuyuiujkmlmkyyhoiuiklmm:jhgyujhu p^pouiuytrfghu,jkopij,ought,rough}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = ['thus', 'theiuygjhkkllmetgfferuyuiujkmlmkyyhoiuiklmm:jhgyujhu p^pouiuytrfghu', 'thjkopij', 'thought', 'through']  #large string\n",
    "factorize_list_of_strings(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thus{,}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = ['thus','thus']\n",
    "factorize_list_of_strings(list_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_common_ending_string(list_words):\n",
    "    \"\"\"\n",
    "    return the common string at end of words    \"\"\"\n",
    "    common = list_words[0]\n",
    "    for word in list_words[1:]:\n",
    "        i = -1\n",
    "        while (i >= -len(word) and i >= -len(common)): #starting the analysis from the end\n",
    "            if(common[i] != word[i]):\n",
    "                break\n",
    "            i -= 1\n",
    "        if i == -1:\n",
    "            common = ''\n",
    "        else:\n",
    "            common = common[(i+1):]\n",
    "    return common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_non_common_end(list_words, common):\n",
    "    \"\"\"\n",
    "    return the list of remaining strings    \"\"\"\n",
    "\n",
    "    list_non_common = list()\n",
    "    for word in list_words:\n",
    "        i = -1\n",
    "        while i >= -len(common) and i >= -len(word): #starting the analysis from the end\n",
    "            if(common[i] != word[i]):\n",
    "                break\n",
    "            i -= 1\n",
    "        if i == -1:\n",
    "            list_non_common.append(word)\n",
    "        else:\n",
    "            list_non_common.append(word[:(i+1)])\n",
    "    return list_non_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def factorize_list_of_strings_double_sided(list_words):\n",
    "    \"\"\" return the factorized expression\n",
    "    \n",
    "    Looks for tthe common string in the beginning and takes it out of the list of words\n",
    "    then looks for the common string in the end of the words, and returns the factorized\n",
    "    expression.\n",
    "    \"\"\"\n",
    "    common_start = find_common_starting_string(list_words)\n",
    "    list_non_common_start = extract_non_common_start(list_words, common_start)\n",
    "    common_end = find_common_ending_string(list_non_common_start)\n",
    "    list_non_common_end = extract_non_common_end(list_non_common_start, common_end)\n",
    "    return common_start + '{' + ','.join(list_non_common_end) + '}' + common_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_words = ['this','thinks','thesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'th{i,ink,esi}s'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorize_list_of_strings_double_sided(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{this,,thesis}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = ['this','','thesis'] #with empty string\n",
    "factorize_list_of_strings_double_sided(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'th{i,i,esy}s'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = ['this','this','thesys'] #same word\n",
    "factorize_list_of_strings_double_sided(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'th{is,is,esi}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = ['this','this','thesi'] #no common in the end\n",
    "factorize_list_of_strings_double_sided(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this{,}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_words = ['this','this'] #all same\n",
    "factorize_list_of_strings_double_sided(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
