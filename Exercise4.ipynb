{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_bookings = \"Documents/bookings.csv.bz2\"\n",
    "file_searches = \"Documents/searches.csv.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_bookings = pd.read_csv(file_bookings, sep=\"^\", compression=\"bz2\", chunksize=1000000)\n",
    "data_searches = pd.read_csv(file_searches, sep=\"^\", compression=\"bz2\", chunksize=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Distribute bookings and searches files over a million lines files</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kenza\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py:175: DtypeWarning: Columns (40,41,42,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "C:\\Users\\Kenza\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py:175: DtypeWarning: Columns (29,30,31,32,33,34,35,36,37,38,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  shell.run_cell(code, store_history=store_history, silent=silent)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 13 14 15 16 17 18 19 20\n"
     ]
    }
   ],
   "source": [
    "def create_chunk_files(data_reader, str_name):\n",
    "    i = 0\n",
    "    for chunk in data_reader:\n",
    "        fle = open('Documents/{}_chunks_{}'.format(str_name, i), mode='w')\n",
    "        chunk.to_csv(fle, sep='^', index=False)\n",
    "        print(i),\n",
    "        fle.close()\n",
    "        i += 1\n",
    "        \n",
    "create_chunk_files(data_bookings, 'bookings')\n",
    "create_chunk_files(data_searches, 'searches')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Preprocess the bookings by extracting possible tupes (date, origin, destination).</li>\n",
    "<li>Taking date into account as, e.g. a search made after a booking is not a search that ended up to a booking, so date needs to match as well.</li>\n",
    "<li>Create tuples and save them in file.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "list_tuples = list()\n",
    "\n",
    "def get_tuples(x):\n",
    "    cre_date = string.split(x['cre_date'], sep=' ')[0]\n",
    "    global list_tuples\n",
    "    tuple_info = [cre_date, x['dep_port'], x['arr_port']]\n",
    "    if tuple_info not in list_tuples:\n",
    "        list_tuples.append(tuple_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded file nb 0\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 1\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 2\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 3\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 4\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 5\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 6\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 7\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 8\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 9\n",
      "100000 200000 300000 400000 500000 600000 700000 800000 900000 1000000 loaded file nb 10\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "fle = open(\"Documents/tuples\", \"wb\")\n",
    "for booking_file_index in range(11): #we have 11 bookings chunks\n",
    "    data_bookings = pd.read_csv('Documents/bookings_chunks_{}'.format(booking_file_index), sep='\\s*\\^\\s*', engine='python')\n",
    "    print('loaded file nb {}'.format(booking_file_index))\n",
    "    i = 0\n",
    "    while i < len(data_bookings):   #process each chunk in groups of 1000 lines\n",
    "        list_tuples = list()\n",
    "        data_chunk = data_bookings[i:(i+1000)]\n",
    "        i += 1000\n",
    "        if i % 100000 == 0:\n",
    "            print(i),\n",
    "        f = data_chunk.apply(get_tuples, axis=1)   #apply get_tuples() on the different rows to extract the tuples\n",
    "        pickle.dump(list_tuples, fle)\n",
    "fle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>read tuples and look for the searches entries that match the booking tuples in date, origin and destination of flight</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fle_date = open(\"Documents/tuples\", 'rb')\n",
    "tuples_date = list()\n",
    "while 1:\n",
    "    try:\n",
    "        list_chunk = pickle.load(fle_date)\n",
    "        tuples_date += list_chunk\n",
    "    except EOFError:\n",
    "        break\n",
    "fle_date.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_matches_date(x):\n",
    "    global tuples_date\n",
    "    global res\n",
    "    tuple_info = [x['Date'], x['Origin'], x['Destination']]\n",
    "    #tuple_info = [x['Origin'], x['Destination']]\n",
    "    if tuple_info in tuples_date:\n",
    "        res.append(1)\n",
    "    else:\n",
    "        res.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded file nb 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-205-9e21f29bd4f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mdata_chunk_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_searches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_chunk_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_matches_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kenza\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   3970\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3971\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3972\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3973\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3974\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kenza\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4024\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4025\u001b[0m                 result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[1;32m-> 4026\u001b[1;33m                                     labels=labels)\n\u001b[0m\u001b[0;32m   4027\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4028\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.reduce (pandas\\lib.c:43773)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\src\\reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.Reducer.get_result (pandas\\lib.c:33913)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-197-df25e66f74e7>\u001b[0m in \u001b[0;36mfind_matches_date\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mtuples_date\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtuple_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Origin'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Destination'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#tuple_info = [x['Origin'], x['Destination']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtuple_info\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples_date\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kenza\\Anaconda2\\lib\\site-packages\\pandas\\core\\series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kenza\\Anaconda2\\lib\\site-packages\\pandas\\core\\index.pyc\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   1776\u001b[0m         \u001b[1;31m# if we have something that is Index-like, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m         \u001b[1;31m# use this, e.g. DatetimeIndex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1778\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'_values'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1779\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kenza\\Anaconda2\\lib\\site-packages\\pandas\\core\\series.pyc\u001b[0m in \u001b[0;36m_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;34m\"\"\" return the internal repr of this data \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_search_new = open(\"Documents/searches_with_matches_date.csv\", 'w')\n",
    "for searching_file_index in range(21):\n",
    "    data_searches = pd.read_csv('Documents/searches_chunks_{}'.format(searching_file_index), sep='^', engine='python')\n",
    "    print('loaded file nb {}'.format(searching_file_index))\n",
    "    \n",
    "    i = 0\n",
    "    res = list()\n",
    "    while i < len(data_searches):\n",
    "        data_chunk_search = data_searches[i:(i+100)]\n",
    "        i += 100\n",
    "        f = data_chunk_search.apply(find_matches_date, axis=1)\n",
    "        \n",
    "        if i % 100:\n",
    "            print(i),\n",
    "    data_searches.loc[:,'MatchesBookings'] = pd.Series(res)\n",
    "    if searching_file_index == 0:\n",
    "        data_searches.to_csv(file_search_new, sep='^', index=False)\n",
    "    else:\n",
    "        data_searches.to_csv(file_search_new, sep='^', index=False, header=False)\n",
    "    break\n",
    "\n",
    "file_search_new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
